{
  "task_name": "word_search_ii",
  "model": "qwen2.5-coder:3b",
  "timestamp": "2026-02-22T18:35:32.903886",
  "nl_problem": "# Task: word_search_ii\n# Interface:\nClass: Solution\nMethod: findWords(self, arg1, arg2)\n\nGiven an m x n board of characters and a list of strings words, return all words on the board.\nEach word must be constructed from letters of sequentially adjacent cells, where adjacent cells are horizontally or vertically neighboring. The same letter cell may not be used more than once in a word.\nYou should use a Trie data structure to optimize the search.\n\nConstraints:\n- m == board.length\n- n == board[i].length\n- 1 <= m, n <= 12\n- board and words consist of lowercase English letters.\n- 1 <= words.length <= 3 * 10^4\n- All strings in words are unique.",
  "lisp_spec": "(task\n  (name \"word_search_ii\")\n  (signature ( (board list) (words list) ) list)\n  (constraints\n    (constraint \"m == board.length\")\n    (constraint \"n == board[i].length\")\n    (constraint \"1 <= m, n <= 12\")\n    (constraint \"board and words consist of lowercase English letters.\")\n    (constraint \"1 <= words.length <= 3 * 10^4\")\n    (constraint \"All strings in words are unique.\")\n  )\n  (goal\n    (description \"Return all words on the board that can be formed by sequentially adjacent cells, where adjacent cells are horizontally or vertically neighboring. The same letter cell may not be used more than once in a word.\")\n    (rule \"Use a Trie data structure to optimize the search.\")\n    (return \"A list of all valid words found on the board.\")\n  )\n)",
  "generated_code": "# solution.py\nfrom typing import List, Optional, Dict, Set, Any\nimport heapq\nimport collections\n\nclass TrieNode:\n    def __init__(self):\n        self.children: Dict[str, 'TrieNode'] = {}\n        self.is_end_of_word: bool = False\n\nclass Trie:\n    def __init__(self):\n        self.root: TrieNode = TrieNode()\n\n    def insert(self, word: str) -> None:\n        node = self.root\n        for char in word:\n            if char not in node.children:\n                node.children[char] = TrieNode()\n            node = node.children[char]\n        node.is_end_of_word = True\n\n    def search(self, word: str) -> bool:\n        node = self.root\n        for char in word:\n            if char not in node.children:\n                return False\n            node = node.children[char]\n        return node.is_end_of_word\n\nclass Solution:\n    def findWords(self, board: List[List[str]], words: List[str]) -> List[str]:\n        trie = Trie()\n        for word in words:\n            trie.insert(word)\n\n        m, n = len(board), len(board[0])\n        directions = [(0, 1), (1, 0), (-1, 0), (0, -1)]\n        visited: Set[tuple[int, int]] = set()\n\n        def dfs(x: int, y: int, node: TrieNode, path: List[str]) -> None:\n            if node.is_end_of_word:\n                result.add(''.join(path))\n            for dx, dy in directions:\n                nx, ny = x + dx, y + dy\n                if 0 <= nx < m and 0 <= ny < n and (nx, ny) not in visited:\n                    visited.add((nx, ny))\n                    path.append(board[nx][ny])\n                    dfs(nx, ny, node.children[board[nx][ny]], path)\n                    path.pop()\n                    visited.remove((nx, ny))\n\n        result: Set[str] = set()\n        for i in range(m):\n            for j in range(n):\n                if board[i][j] in trie.root.children:\n                    visited.add((i, j))\n                    dfs(i, j, trie.root.children[board[i][j]], [board[i][j]])\n                    visited.remove((i, j))\n\n        return list(result)",
  "test_passed": false,
  "test_output": "============================= test session starts ==============================\nplatform linux -- Python 3.12.3, pytest-8.3.5, pluggy-1.6.0\nrootdir: /media/developer/USB480G/Project/llm_complexity_benchmark\nplugins: cov-7.0.0, langsmith-0.4.41, anyio-4.11.0\ncollected 2 items\n\n01_TestDefinitions/word_search_ii/test_solution.py F.                    [100%]\n\n=================================== FAILURES ===================================\n__________________________ test_word_search_ii_basic ___________________________\n\n    def test_word_search_ii_basic():\n        solution = Solution()\n        board = [[\"o\",\"a\",\"a\",\"n\"],[\"e\",\"t\",\"a\",\"e\"],[\"i\",\"h\",\"k\",\"r\"],[\"i\",\"f\",\"l\",\"v\"]]\n        words = [\"oath\",\"pea\",\"eat\",\"rain\"]\n>       assert sorted(solution.findWords(board, words)) == sorted([\"eat\",\"oath\"])\n\n01_TestDefinitions/word_search_ii/test_solution.py:8: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n01_TestDefinitions/word_search_ii/solution.py:58: in findWords\n    dfs(i, j, trie.root.children[board[i][j]], [board[i][j]])\n01_TestDefinitions/word_search_ii/solution.py:49: in dfs\n    dfs(nx, ny, node.children[board[nx][ny]], path)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nx = 0, y = 1, node = <solution.TrieNode object at 0x7bd9529d7d40>\npath = ['o', 'a', 'a']\n\n    def dfs(x: int, y: int, node: TrieNode, path: List[str]) -> None:\n        if node.is_end_of_word:\n            result.add(''.join(path))\n        for dx, dy in directions:\n            nx, ny = x + dx, y + dy\n            if 0 <= nx < m and 0 <= ny < n and (nx, ny) not in visited:\n                visited.add((nx, ny))\n                path.append(board[nx][ny])\n>               dfs(nx, ny, node.children[board[nx][ny]], path)\nE               KeyError: 'a'\n\n01_TestDefinitions/word_search_ii/solution.py:49: KeyError\n=========================== short test summary info ============================\nFAILED 01_TestDefinitions/word_search_ii/test_solution.py::test_word_search_ii_basic\n========================= 1 failed, 1 passed in 0.07s ==========================\n",
  "test_errors": "",
  "complexity_metrics": {
    "total_complexity_score": 0.3701,
    "python": {
      "cyclomatic_avg": 2.6,
      "cyclomatic_max": 5,
      "wmc": 13,
      "maintainability_index": 52.67543386849091,
      "max_nesting_depth": 5,
      "halstead_volume": 0,
      "lloc": 56,
      "loc": 61
    },
    "lisp": {
      "lisp_max_depth": 4,
      "lisp_constraints": 7,
      "lisp_rules": 1,
      "lisp_token_count": 113
    }
  }
}