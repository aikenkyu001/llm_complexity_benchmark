{
  "task_name": "word_ladder_v2_branching",
  "model": "falcon3:10b",
  "timestamp": "2026-02-20T15:08:04.672110",
  "nl_problem": "# Task: word_ladder_v2_branching\n# Interface:\nClass: Solution\nMethod: ladderLength(self, arg1, arg2, arg3)\n\nGiven two words, beginWord and endWord, and a dictionary's word list, find the length of the shortest transformation sequence from beginWord to endWord.\nThis is a complex version with multiple additional rules:\n1. You MUST use a Bidirectional BFS to minimize the search space.\n2. For each word transformation, you must check a 'forbidden_combinations' list (not provided, assume a helper `is_forbidden(word1, word2)` exists or handle it as a potential constraint).\n3. The wordList can be very large; prioritize memory efficiency.\n4. Return 0 if no path exists.\n\nConstraints:\n- Word length up to 20.\n- wordList size up to 10^5.\n- beginWord and endWord are different.",
  "lisp_spec": "(task\n (name \"ladderLength\")\n (signature ( (self) (beginWord string) (endWord string) (wordList (list string)) ) int)\n (constraints\n   (constraint \"Word length up to 20.\")\n   (constraint \"wordList size up to 10^5.\")\n   (constraint \"beginWord and endWord are different.\")\n )\n (goal\n   (description \"Find the length of the shortest transformation sequence from beginWord to endWord using Bidirectional BFS.\")\n   (rule \"Use a Bidirectional BFS to minimize the search space.\")\n   (rule \"Check for forbidden combinations using a helper function or handle as a constraint.\")\n   (rule \"Prioritize memory efficiency due to potentially large wordList.\")\n   (return \"Return 0 if no path exists.\")\n )\n)",
  "generated_code": "from typing import List, Optional, Dict, Set, Any\nimport heapq\nimport collections\n\nclass Node:\n    def __init__(self, word: str, dist: int):\n        self.word = word\n        self.dist = dist\n\n    def __lt__(self, other):\n        return self.dist < other.dist\n\nclass Solution:\n    def ladderLength(self, beginWord: str, endWord: str, wordList: List[str]) -> int:\n        if endWord not in wordList:\n            return 0\n\n        wordSet = set(wordList)\n        queue_start = collections.deque([Node(beginWord, 1)])\n        queue_end = collections.deque([Node(endWord, 1)])\n        visited_start = {beginWord}\n        visited_end = {endWord}\n\n        while queue_start and queue_end:\n            node_start = queue_start.popleft()\n            node_end = queue_end.popleft()\n\n            if self.is_neighbor(node_start.word, node_end.word):\n                return min(node_start.dist, node_end.dist)\n\n            for neighbor in self.get_neighbors(node_start.word, wordSet):\n                if neighbor not in visited_start:\n                    visited_start.add(neighbor)\n                    queue_start.append(Node(neighbor, node_start.dist + 1))\n\n            for neighbor in self.get_neighbors(node_end.word, wordSet):\n                if neighbor not in visited_end:\n                    visited_end.add(neighbor)\n                    queue_end.append(Node(neighbor, node_end.dist + 1))\n\n        return 0\n\n    def is_neighbor(self, word1: str, word2: str) -> bool:\n        diff_count = sum(ch1 != ch2 for ch1, ch2 in zip(word1, word2))\n        return diff_count == 1\n\n    def get_neighbors(self, word: str, wordSet: Set[str]) -> List[str]:\n        neighbors = []\n        for i in range(len(word)):\n            for char in 'abcdefghijklmnopqrstuvwxyz':\n                new_word = word[:i] + char + word[i+1:]\n                if new_word in wordSet:\n                    neighbors.append(new_word)\n        return neighbors",
  "test_passed": false,
  "test_output": "============================= test session starts ==============================\nplatform darwin -- Python 3.14.3, pytest-9.0.2, pluggy-1.6.0\nrootdir: /private/test/llm_complexity_benchmark\nplugins: anyio-4.12.1\ncollected 2 items\n\n01_TestDefinitions/word_ladder_v2_branching/test_solution.py FF          [100%]\n\n=================================== FAILURES ===================================\n__________________________ test_word_ladder_v2_basic ___________________________\n\n    def test_word_ladder_v2_basic():\n        solution = Solution()\n        beginWord = \"hit\"\n        endWord = \"cog\"\n        wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\",\"cog\"]\n>       assert solution.ladderLength(beginWord, endWord, wordList) == 5\nE       AssertionError: assert 3 == 5\nE        +  where 3 = ladderLength('hit', 'cog', ['hot', 'dot', 'dog', 'lot', 'log', 'cog'])\nE        +    where ladderLength = <solution.Solution object at 0x1066d70e0>.ladderLength\n\n01_TestDefinitions/word_ladder_v2_branching/test_solution.py:9: AssertionError\n___________________________ test_word_ladder_v2_long ___________________________\n\n    def test_word_ladder_v2_long():\n        solution = Solution()\n        beginWord = \"aaaaa\"\n        endWord = \"bbbbb\"\n        wordList = [\"aaaab\",\"aaabb\",\"aabbb\",\"abbbb\",\"bbbbb\"]\n>       assert solution.ladderLength(beginWord, endWord, wordList) == 6\nE       AssertionError: assert 3 == 6\nE        +  where 3 = ladderLength('aaaaa', 'bbbbb', ['aaaab', 'aaabb', 'aabbb', 'abbbb', 'bbbbb'])\nE        +    where ladderLength = <solution.Solution object at 0x106741310>.ladderLength\n\n01_TestDefinitions/word_ladder_v2_branching/test_solution.py:16: AssertionError\n=========================== short test summary info ============================\nFAILED 01_TestDefinitions/word_ladder_v2_branching/test_solution.py::test_word_ladder_v2_basic\nFAILED 01_TestDefinitions/word_ladder_v2_branching/test_solution.py::test_word_ladder_v2_long\n============================== 2 failed in 0.03s ===============================\n",
  "test_errors": "",
  "complexity_metrics": {
    "total_complexity_score": 0.3963,
    "python": {
      "cyclomatic_avg": 3.4,
      "cyclomatic_max": 9,
      "wmc": 17,
      "maintainability_index": 45.78150186811509,
      "max_nesting_depth": 5,
      "halstead_volume": 0,
      "lloc": 44,
      "loc": 54
    },
    "lisp": {
      "lisp_max_depth": 5,
      "lisp_constraints": 4,
      "lisp_rules": 3,
      "lisp_token_count": 94
    }
  }
}